# Full Safety Optimized robots.txt

# 1. Allow all search engines to crawl important pages
User-agent: *
Disallow: /admin/
Disallow: /config/
Disallow: /private/
Disallow: /backups/
Disallow: /database/
Disallow: /temp/
Disallow: /login/
Disallow: /signup/
Disallow: /server-status
Disallow: /api/

# 2. Block crawling of unnecessary file types
Disallow: /*.php$
Disallow: /*.sql$
Disallow: /*.env$
Disallow: /*.log$
Disallow: /*.bak$
Disallow: /*.zip$

# 3. Prevent crawling of dynamic query strings
Disallow: /*?*

# 4. Block bad bots (replace with known malicious bots if any)
User-agent: BadBot
Disallow: /
User-agent: EvilScraper
Disallow: /
User-agent: 008
Disallow: /

# 5. Provide sitemap location
Sitemap: https://www.yourwebsite.com/sitemap.xml
